{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911e98a5",
   "metadata": {},
   "source": [
    "# Rapport Projet BOMR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5120d31f",
   "metadata": {},
   "source": [
    "Authors\n",
    "\n",
    "Valentin Suppa-Gallezot   \n",
    "Mehdi El Bouari   \n",
    "Thibault Golaz  \n",
    "Louis Marchand  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854e58d",
   "metadata": {},
   "source": [
    "## 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e94916",
   "metadata": {},
   "source": [
    "### 0.0. Guidlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1227e870",
   "metadata": {},
   "source": [
    "For this project we had to construct and implement a mobile robot able to perform path finding method and movement based on vision-oriented programs. The robot we are using here is a Thymio-II robot.\n",
    "  \n",
    "The code will follow these guidelines:   \n",
    "  \n",
    "•\t**Create an environnment:** Our environnement is made of the thymio detectable thank to 2 green circles, obstacles (represented as black sheets of paper), a target represented by a red square of paper and 3d obstacles used to test local navigation (detected by the thymio sensors).  \n",
    "•\t**Find the best path:** The objective is that the Thymio goes its initial position in the map to a target in the environement.  \n",
    "•\t**Motion control:** To control the robot we use functions to correct the angle and close the position to the next goal that is updated upon reach.  \n",
    "•   **Kalman filter:** In the case where we don't have data from the camera we use, we apply a Kalman filter knowing the last detected/predicted position and the speed given by the robot to compute the next position.  \n",
    "•\t**Local navigation:** While moving, the Thymio has to use local navigation to avoid physical obstacles that can be put in its path at any point in time.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419c9d4",
   "metadata": {},
   "source": [
    "### 0.1. General overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47155b",
   "metadata": {},
   "source": [
    "<img src=\"pictures/Diagram.png\" width=700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a9ef3",
   "metadata": {},
   "source": [
    "## 1. Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1e7b0",
   "metadata": {},
   "source": [
    "### 1.0 Most important function in Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de6c51",
   "metadata": {},
   "source": [
    "| Function of Vision | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|`detect_start(image, show=False, begin = True)` |receive a frame when the program starts, show allows to plot the image and begin allows to get only the start_coordinates|An image with a white rectangle on the two circles of the thymio and the start coordinates|\n",
    "|`detect_target(image)`|receive a frame when the program starts|An image with a white rectangle on the target and the coordinates of the target|\n",
    "|`detect_obstacle(image)`|receive an image with white rectangle on the start and the target|corner coordinates of each obstacle|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9be852",
   "metadata": {},
   "source": [
    "### 1.1. Start and target Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec63ab",
   "metadata": {},
   "source": [
    "In order to obtain the starting point and the target point, we used two colored circles (1 blue and 1 green) of different sizes. These two circles are placed on the robot. At the beginning of the program, a picture of the scene is taken. Using the library opencv and more precisely the function template matching the center of the two circles are detected. Then by just computing the middle of these centers the center of the thymio (called starting point in the program is detected). Two circles are needed because in the following of the code it will allow to compute the orientation of the thymio  \n",
    "The same method is used to get the target but a red rectangle is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616ff01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code refer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347f145",
   "metadata": {},
   "source": [
    "Since the starting point and the goal are detected it is time to compute the coordinates of the obstacle on the map. In our project the obstacles are black 2 dimensions shapes. They are positionned randomly on the field. In order to detect them the image is converted in black and white. To avoid some risk of confusion with the shapes on the thymio and the one for the target, white rectangles are drawn on them. Then, after applying the threshold, the obstacle are detected (#plot image). By using an opencv function, the coordinates of the contours are found. Finaylly by following the steps of this link https://stackoverflow.com/questions/50984205/how-to-find-corners-points-of-a-shape-in-an-image-in-opencv every corner coordinates of each shape are stored in a array. It will be helpful to compute the visibility graph.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae187d",
   "metadata": {},
   "source": [
    "## 2. Global Navigation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db906a16",
   "metadata": {},
   "source": [
    "### 2.0. Main functions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed75533f",
   "metadata": {},
   "source": [
    "This part of the code is the second step of our code, its goal is to compute the shortest path from the starting position of the thymio to the target while avoiding obstacles. All the elements used in this part are given by the vision part of the code they are transmitted as points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6f3ab",
   "metadata": {},
   "source": [
    "| Function of Global Navigation | Input | Output |\n",
    "|:------|:------|:------|\n",
    "|`build_vis_graph(shapes, start, target)` |Takes a list of points representing the contours of the obstacles and two points standing for the starting and finishing goal of the path. The path is made using pyVisgraph library and avoid obstacle using a visibility graph and a djisktra algorithm |The shortest path in the form of a list of points and the shapes representing the obstacles (also represented as points|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40b445",
   "metadata": {},
   "source": [
    "<u>Links of interest:</u>  \n",
    "    - PyVisgraph library: https://github.com/TaipanRex/pyvisgraph  \n",
    "    - D.T. Lee : https://taipanrex.github.io/2016/10/19/Distance-Tables-Part-2-Lees-Visibility-Graph-Algorithm.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd25bb",
   "metadata": {},
   "source": [
    "### 2.1. PyVisgraph library "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ecfdc",
   "metadata": {},
   "source": [
    "Given a set of simple obstacle polygons, build a visibility graph and find the shortest path between two points.\n",
    "Pyvisgraph is a MIT-licensed Python package for building visibility graphs from a list of simple obstacle polygons. The visibility graph algorithm (D.T. Lee) runs in O(n^2 log n) time. The shortest path is found using Djikstra's algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6a16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608105f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b54078",
   "metadata": {},
   "source": [
    "## 3. Motion Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b84b4",
   "metadata": {},
   "source": [
    "## 4. Local avoidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287aca8f",
   "metadata": {},
   "source": [
    "## 5. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7cb61",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6bddcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
